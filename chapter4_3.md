<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
 tex2jax: {
 inlineMath: [['$', '$'] ],
 displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
 }
 });
</script>

# 4.3 音声処理

- **音声生成(Speech Synthesis)**: 人間の音声を人工的に合成すること
- **音声認識(Speech Recognition)**: 音声波形からスペクトル（波形を短時間で切った周波数成分）を作成し、数理モデルを使って内容を推定すること

## 音声認識の基本プロセス

1. 音声をデジタル情報に変換する
2. 音声波形から周波数や時間変化などの特徴を抽出する
3. 言葉の最小単位である**音素**を特定する
4. 辞書と照合することで音素列を単語に変換する
5. 単語間のつながりを解析して、文章を生成する

## 音声のデジタルデータの変換

デジタルデータの変換は、画像の場合と同じで**標本化(サンプリング)**、**量子化**、**符号化**の流れになる。

- 標本化: 連続的な音波を一定の時間間隔ごとに切り出す（画像であれば格子状に切り出して画素とした）
- 量子化: 波の強さを離散的な値に近似する
- 符号化: 量子化された値をビット列で表現する

**パルス符号変調(PCM: Pulse Code Modulration)** は、音声のAD変換でよく用いられる手法。アナログ信号の強度を一定間隔で標本化（サンプリング）し、整数値として量子化し、最後にビット列で表現する。

**音声の標本化**

- **サンプリングレート**: １秒間に音波の情報を数値に変換する回数。CDの音声は、**サンプリング周波数44.1kHz**で、**１秒あたり44100回信号を測定し記録する**ことを意味している。
- **サンプリング定理**: CDを再生するとき、再生装置では半分の22.05Hzまでしか再現ができない。サンプリング定理とは、AD変換でデジタル信号に変換する際、再現したい信号に含まれる最大周波数の２倍を超えるサンプリング周波数で標本化を行う必要がある、というもの。  
人間が20kHzよりも高い周波数は聞こえないとされているため、CDはその２倍を超える周波数で標本化されている。

**音声の量子化**

量子化ビット数で表されるビット数で数値化される。

CDは16ビット、ハイレゾ音源は24ビット。

**音声の符号化**

量子化された値をビット列で表現するが、さらにデータ圧縮を行ってデジタルデータに変換する。

**音声のデータ量**

サンプリングレート、量子化ビット数、音声の長さによってデータ量は決まる。

例) 50kHz、量子化ビット16ビット、30秒の音声のデータ量  

$50,000\text{kHz} \times 16\text{bits} \times 30\text{秒} = 24,000,000 \text{bits} = 3\text{MB}$

データ量は１秒あたりのデータ量として表すこともある。CDの例では44,100x16bit=705.6kbpsになる。CDはステレオ音源のため、左右のデータ量をあわせると倍になる。

## 音声データの保存フォーマット

- WAV ... 非圧縮のフォーマット。高音質だがデータ量が大きい
- MP3 ... 圧縮されているためデータ量が小さい。非可逆。
- FLAC ... 可逆圧縮を用いる

## 周波数成分の抽出

**高速フーリエ変換**は、音声信号を、周波数成分の分布を表す周波数スペクトルに高速に変換する手法。周波数ごとの振幅の大きさに分解する。

**スペクトル包絡**は、波数スペクトル上で各周波数成分のピークを滑らかに結んだ曲線。色や音声の特徴を表す上で重要な役割を果たす。スペクトル包絡は、短時間フーリエ変換やケプストラム分析などの手法で周波数成分に分析した後、得られたスペクトルの傾向を滑らかに結んで生成される。

**フォルマント周波数**は、スペクトル包絡においてピークが立っている複数の周波数。

**音韻**は、言語に依存せずに人の発生を区別できる音の要素。音韻が近ければフォルマント周波数も近い値を取る。

## 音響モデル

音響モデルとして長く用いられてきたのは**隠れマルコフモデル(HMM: Hidden Markkov Model)**。音素（母音や子音など）ごとに学習を行い、音素列がどの単語に対応するかを判断するために、事前に用意された音素列と単語を対応させた辞書を使ってパターンマッチングを行う。

## 音声生成の技術

text-to-speech TTSの手法

- **波形接続TTS**: 文字回音声の断片の集合体から必要なものを結合して音声を合成する。声を変えたり抑揚や感情を加えることが難しい傾向にある。
- **パラメトリックTTS**: 音声の波形をモデル化して、文法、口の動き、高さ、抑揚などの特徴に関するパラメータに基づいて波形を生成する

パラメトリックTTSの方が低コストかつ高速に処理が可能だが、人間らしさの観点から波形接続TTSに劣る。

従来の音声合成では、声の高さと音色の２つの特徴を空いていするために、発生メカニズムに基づいた数理モデルが使われていた。数理モデルによる音声合成では、確率的なアプローチを用いていた。代表的なモデルは「**混合正規分布モデル**」と「**隠れマルコフモデル**」である。

2010年代以降、ニューラルネットワークを用いたモデルが普及。Microsoftが発表した**DNN-HMM**は、HMMとDNNを組み合わせたもの。その後、ディープラーニングを用いた音声処理ネットワークが主流に。2016年にDeepMindが発表した**WaveNet**は音声合成にブレークするーをもたらした。

