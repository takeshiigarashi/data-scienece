# 7.7 言語モデルと生成AIに関する課題

## 生成AIに関する法的な問題

- 著作権の侵害
- 秘密情報の漏洩
- プライバシーの侵害

著作権法のもとで、著作物の条件に「十分な創作性を持つ表現物」であることが含まれている。生成AIが生成した文章は、そのまま、著作物として認められる可能性は低い。一方で、AIの支援を受けて生成したものが著作物になる可能性はある。

- AIの生成物をそのまま利用せず、そこからアイデアをもらって新しく創作をする
- AIの生成物の顕著な一部分を創作的に編集して活用する

## 生成AIと著作権侵害のリスク

AIの学習データとして、他社の著作物を無断で使用することを特例として認める著作権法上の規定がある。一方、生成AIに著作物を学習させた場合、その学習済みモデルによる生成物が著作権侵害を起こしやすいことに注意が必要。生成プロセスにおいて、他人の著作物を入力し、他人の直鎖物に依拠した生成物を出力させる行為は、著作権法で禁じられている複製・翻案に該当するためである。

ただし、私的な範囲での複製は著作権法で認められている。

## 生成AIと個人情報・機密情報の問題

個人情報を入力することは、OpenAI社への個人情報の提供に該当する。
これは、学習に利用されるかどうかとは関係がないことに注意が必要。

## 生成AIの倫理的な問題

以下のような倫理的な課題が注目されている

- 出力における差別やバイアスをなくす
- モデルの透明性と解釈可能性を改善する
- AIの民主化を促進し、幅広い層にアクセス可能な技術にする

学習データ自体は人間が作成したものでもあるので、人間社会に潜むバイアスに影響されやすい。なるべ多様性をもたせるような工夫がされているものの、センシティブな属性は生成された文章の公平性に影響を及ぼす可能性がある。

## 法規制と国内外のガイドライン

法規制は不十分。OpenAIなどは利用規約で禁止事項を明確にしている。

医療、経済、法律といった高リスクの専門分野では生成AIの利用が厳しく規制されている。

**ハードローとソフトロー** 法的な拘束力のある法律や条例をハードローという。法律上強制力をもたないようなガイドライン、自主規制、推奨事項などをソフトローという。
現在、日本や米国はソフトローを中心に採用し、EUや中国は罰則を伴うハードローを採用する傾向にある。

日本では、2023年12月に**AI事業者ガイドライン案**が提出され、2024年1月に正式に公表された。AI開発者、AI提供者、AI利用者に分けて、それぞれが留意すべき事項や必要な取り組みが示されている。

**EUのAI規制の動向** 2023年5月以降、AI規制法が可決されている。生成AIの提供事業者には以下の義務を課している。

- 透明性確保の義務
- AI生成物に関して、AIによる生成を明記する
- 著作物で保護されたデータをAIの学習に利用した場合は公表し、詳細な要約を提供する
- EU法に違反するコンテンツ生成に対するセーフガードの確率

**米国のAI規制の動向** 2022年10月にAI権利章典として、AIシステムの開発の非拘束的な５つの原則を公開している。

2023年7月には、AIの開発企業7社と米政府が、AIがもたらす様々なリスクに対処することを自主的な拘束としてまとめた。