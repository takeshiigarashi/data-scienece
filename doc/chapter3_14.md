<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
 tex2jax: {
 inlineMath: [['$', '$'] ],
 displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
 }
 });
</script>

# 3.14 モデルの精度評価

## データ分割の方法

**ホールドアウト法** 学習データを訓練データとテストデータの２つに一度わけるだけ。訓練:テストを7:3または8:2とする場合が多い。

- <u>データ量が大きいときでも</u>、比較的短時間で精度スコアを算出できる
- 一方で、分割後のデータに偏りが生じると、精度検証結果の信頼性が落ちる。特にデータ量が少ないときは注意が必要。

**交差検証法** 

- データ全体をK個のグループに分ける
- １つをテストデータ、残るK-1個を訓練データにとして、学習と精度の評価を行う
- 別のグループをテストデータとして、同じように学習と精度の評価を行う
- K個の精度評価の結果を平均してモデルの精度とする
- <u>データが少なくても</u>信頼できる精度評価が得られる
- <u>計算の量やかかる時間は大きくなる</u>

## 精度評価のための指標

### 混同行列

|            |予測結果が0                   |予測結果が1
|------------|----------------------------|-----------------------------
|正解クラスが0 |真陰性のデータ数(TrueNegative) |偽陽性のデータ数(FalsePositive) 
|正解クラスが1 |偽陰性のデータ数(FalseNegative)|真陽性のデータ数(TruePositive)

- **真陰性** 予想結果が0（陰性）で、予想結果が正しい
- **偽陰性** 予想結果が0（陰性）で、予想結果が誤っている
- **真陽性** 予想結果が1（陽性）で、予想結果が正しい
- **偽陽性** 予想結果が1（陽性）で、予想結果が誤っている

### 精度指標

#### 正解率(Accuracy)

全体に対する真陰性、真陽性の割合（予想結果が正しい割合）

$$\frac{真陽性(TP) + 真陰性(TN)}{全体}$$

#### 適合率(Precision)

陽性判定されたデータのうち、実際に陽性だったデータの割合。

$$\frac{真陽性(TP)}{真陽性(TP)+偽陽性(FP)}$$

- 陽性判定の正確性を示す指標。
- 偽陽性を避けたいときに注目。
- <u>適合率を重要視する場合</u>、偽陽性を少なくしたくなるため、陽性判断の基準が厳しくなる。そのため、陽性の可能性があっても陰性と判断されやすくなり、<u>偽陰性のデータが多くなる</u>。<u>偽陰性のデータが多くなると、再現率は下がる</u>ことになる。(※)
- <u>病気診断では、偽陰性は避けたいので、適合率を重視すべきではない。</u>

#### 再現率(Recall)

陽性データのうち、陽性として検出されたデータの割合。

$$\frac{真陽性(TP)}{偽陰性(FN)+真陽性(TP)}$$

- 陽性だったデータのうち、陽性と検出できた割合.
- 陽性を見落としてしまうリスクが高いときに注目。
- <u>再現率を重要視する場合</u>、陽性の検出をしやすくしたくなるため、陽性判断の基準が緩くなる。そのため、<u>偽陽性のデータが多くなる</u>。<u>偽陽性のデータが多くなると、適合率は下がる</u>ことになる。(※)
- 病気診断では、偽陽性は再検査すれば誤診を避けられるため、偽陰性ほど深刻ではない。

(※) **適合率と再現率はトレードオフ関係になる**

#### F値(F-measure)

適合率と再現率の調和平均

$$\frac{2 \times 適合率(Precision) \times 再現率(Recall)}{適合率(Precision)+再現率(Recall)}$$

混合行列や適合率、再現率は分類タスクの評価に使う。回帰タスクなどのほかのタスクには使えない。

## ROC曲線、AUCを用いた評価

正解率（Accuracy）、適合率（Precision）、再現率（Recall）は、**二値分類問題のしきい値の設定に依存して評価が変わりやすい**、という課題がある。「**ROC曲線**」は、二値分類のしきい値に依存しない手法。（ROC: Receiver Operating Characteristic）

ROC曲線は、**真陽性率**と**偽陽性率**を用いて定義される。二値分類問題のしきい値を少しずつ変化させた際の、真陽性率と偽陽性率をプロットすることで形成された曲線（真陽性率を縦軸、偽陽性率を横軸にプロットする）。

### 真陽性率 (TPR: True Positive Rate)

$$\frac{真陽性(TP)}{偽陰性(FN)+真陽性(TP)}$$

- 実際に陽性であるもののうち、陽性と検出された割合。
- 再現率（Recall）と同じ

### 偽陽性率 (FPR: False Positive Rate)

$$\frac{偽陽性(FP)}{真陰性(TN)+偽陽性(FP)}$$

- 実際に陰性であるもののうち、誤って陽性と判断した割合

### AUC

ROC曲線の下の面積をAUCという。

- 完全にランダムに分類する場合、原点から点(1,1)までの直線になり、AUCは0.5になる。
- AUCが0.5というのは、あてずっぽうで判断したことと変わらない、という意味（つまり、精度が全くない、という意味）
- AUCは大きいほど精度がよい

点の意味を考えてみる

- 原点(0,0)は、真陽性率も偽陽性率も0という意味。
  - 真陽性率が0ということは、陽性のデータに対して、予測値が陽性と判断されたデータが0件で、すべて陰性（偽陰性）と判断された、ということ。
  - 偽陽性率が0ということは、陰性のデータに対して、予測値が陽性と判断されたデータも0件ということ。
  - 陽性判定の基準を著しく高く設定して、すべて「陰性」と判断するとこうなる。
- 点(1,1)は、真陽性率も偽陽性率も1という意味。
  - 真陽性率が1ということは、陽性のデータに対して、すべてが「陽性」と判断された、ということ。
  - 偽陽性率が1ということは、陰性のデータに対しても、すべてが「陽性」と判断されたということ。
  - 陽性判断の基準を著しく低く設定して、すべて「陽性」と判断するとこうなる。
- 途中の点は、陽性判断の基準（しきい値）を変えながら採取していく。
  - 真陽性率の方が偽陽性率の方よりも高いとAUCは大きな値になる（ROC曲線が上に膨らむ）。
  - 真陽性率の方が偽陽性率よりも高いとはどういう状態だろうか？
  - 陽性データに対して、陽性判定の割合が大きく（正しく判定できている）、陰性データに対して、偽陽性判定の割合が小さい（正しく判定できている）という状態。つまり、正解率（Accuracy）が上がれば真陽性率があがり偽陽性率もあがることになる。
  - ROC曲線とAUCは、しきい値を変えながらプロットするため、特定のしきい値によらずにモデルの性能を評価できる。


## 回帰問題の精度評価

回帰問題の精度評価は、予測値と正解のズレ・誤算で評価する。小さいほど精度が良い。

### 平均二乗誤差 (MSE: Mean Squared Error)

$$MSE = \frac{1}{N}\sum_{i=1}{N}(y_i - y_{0i})^2$$

ここで$y_i$は予測値、$y_{0i}$は正解値。

### 二乗平均平方根誤差 (RMSE: Root Mean Squared Error)

$$RMSE = \sqrt{\frac{1}{N}\sum_{i=1}{N}(y_i - y_{0i})^2}$$

二乗平均平方根誤差は、MSEの平方根を取った値。
平方根を取ることで、測定値と同じ単位になるため、直感的に捉えやすくなる。

- 誤差値が二乗されているため、大きな誤算ほど大きな重みが付与されている
- 誤差が大きいデータの影響を受けやすいため、外れ値に対して脆弱である

### 平均絶対誤差 (MAE: Mean Absolute Error)

$$MAE = \frac{1}{N}\sum_{i=1}^{N}|y_i - y_{0i}|$$

予測値と正解値の差の絶対値の平均。

誤差を二乗していないため、RMSEに比べると外れ値の影響を受けにくい。

### 回帰係数の標準誤差

回帰係数の標準誤差は、その回帰係数の推定値の精度を示す指標。回帰係数の標準誤差が小さいほど、その回帰係数が母集団の真の回帰係数に近い可能性が高いことを意味する。標準誤差が大きい場合、推定された回帰係数が誤差を含んでいる可能性が高くなる。

回帰係数が統計的に有意かどうかを確認するためにt検定が使われる。

回帰係数の**標準誤差**( $\text{SE}(\hat{\beta})$ )は次式で与えられる。

$$\text{SE}(\hat{\beta}) = \sqrt{\text{Var}(\hat{\beta})} = \sqrt{\sigma^2(\bm{X}^T\bm{X})^{-1}}$$

$\sigma^2$ は**残差分散**といい、次のように計算される。

$$\begin{aligned}
\sigma^2 &= \frac{\sum_{i=1}^n (f(x_i) - y_i)^2}{n-k}
\end{aligned}$$

$k$ は切片を含む回帰係数の個数である。残差分散の分子に現れる式は、**残差平方和**(RSS)という。

$\bm{X}$ は、説明変数のデザイン行列と呼ばれる。
単回帰で、観測データが $(x_1, y_1), \cdots, (x_n, y_n)$ の場合、 $\bm{X}$ は、

$$\bm{X} = ~ \begin{pmatrix}1 & x_1\\
1 & x_2\\
\vdots & \vdots\\
1 & x_n
\end{pmatrix}$$

となる。重回帰で、観測データが $(x_{i1}, \cdots, x_{ip}, y_i) ~~ (i = 1 \cdots n)$ の場合、 $\bm{X}$ は、

$$\bm{X} = ~ \begin{pmatrix}1 & x_{11} & \cdots & x_{1p}\\
1 & x_{21} & \cdots & x_{2p}\\
\vdots & \vdots & \ddots &  \vdots\\
1 & x_{n1} & \cdots & x_{np}
\end{pmatrix}$$

となる。


### 赤池情報量基準 (AIC: Akaike's Information Criterion)

$AIC = -2\text{lnL}(\theta) + 2k$

$\text{lnL}(\theta)$は、**最大対数尤度**といい、**対数尤度関数**に**最尤推定量**($\theta$)を男優したもの。最尤推定量は、モデルのパラメータについての最も尤もらしい推定量のこと。

- 第１項は、モデルがデータとよく一致しているほど小さくなる。対数尤度は、観測値（正解値）と推定量の残差を用いて計算され、<u>モデルがデータとよく一致しているほど、尤度は大きくなる</u>。尤度の対数を取って、正負を逆転させた第１項は、モデルがデータとよく一致しているほど小さくなる。
- 第２項は、「モデルの複雑さ」を表し、説明変数が多いほど大きい値を取り、説明変数が少ないほど小さい値を取る。（過学習を防ぐペナルティ項のようなもの）

<u>AICは何以下であれば良いなどの基準はなく、相対的な評価として用いられる。複数のモデルを比較して評価する必要がある。</u>


## ハイパーパラメータのチューニング

学習前にユーザーが手動で設定するパラメータを**ハイパーパラメータ**という

- ランダムフォレストの弱学習器の数
- ニューラルネットワークの隠れ層の数

ハイパーパラメータは、モデルの複雑さや学習の進行を制御する役割を持っている。汎化性能を高めるために、ハイパーパラメータを調整（チューニング）することがある。

ハイパーパラメータの調整は、 **バリデーションデータ（検証データ）** を用いて行われる。

- 学習データを訓練データとテストデータに分けたあと、訓練データを更に、実際の訓練に使うデータと検証データに分ける。
- ハイパーパラメータを変えながら、実際の訓練データでモデルの学習を行い、検証データで評価する

チューニング方法としては**グリッドサーチ**と**ランダムサーチ**の２つの方法がある。

**グリッドサーチ**: 与えられたパラメータの組み合わせを総当りで試し、ベストな精度を実現する組み合わせを探索する方法

**ランダムサーチ**: パラメータの値の範囲と施行回数を指定し、ランダムな試行により最適なパラメータを探索する方法
