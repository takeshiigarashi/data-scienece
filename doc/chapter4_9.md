<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
 tex2jax: {
 inlineMath: [['$', '$'] ],
 displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
 }
 });
</script>

# 4.9 機械学習における解釈性

## モデルの解釈性とその応用

**ブラックボックス性** ... モデルの判断の根拠が解釈しにくいこと

**大域的な説明(Global Surrogate)** ... モデル全体の各特徴量の寄与度

**局所的な説明(Local Surrogate)** ... 予測対象の１つのサンプル単位での各特徴量の寄与度

## 局所的な説明

特定の１つの入力データに焦点をあてて、そこで得られた予測結果や予測プロセスを説明する手法。

対象サンプルの周辺データに対するモデルの挙動を、別の単純で可読性の高いモデル（線形回帰モデルなど）を利用して説明しようとする。

代表的な技術に **LIME (Local Interpretable Model-agnostic Explanations)** と **SHAP (SHapley Additive exPlanations)** がある。
どちらも、特定のデータサンプルに着目し、単純で解釈しやすい線形回帰モデルで近似することで、予測に寄与する因子を推定するツール。

## 大域的な説明

学習済みモデルがどのようにして予測をするのかをモデル全体の単位で説明する手法。

大域的な説明でも、解釈しやすいオデルで説明する。（説明変数はデータ、目的変数はブラックボックスモデルの予測）。例えば、回帰分析モデルで金獅子、回帰分析モデルを解釈することで、元のニューラルネットワークの解釈を試みる。

画像認識モデルに対しては代表的な技術として**Grad-CAM**がある。CNNモデルの勾配情報を活用し、画像認識を行うモデル全体に対して予測根拠を可視化することを目指す手法。CCNが分類において注文していると推定される範囲をヒートマップで表示することができる。


