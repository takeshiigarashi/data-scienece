<script type="text/javascript" async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.min.js">
</script>
<script type="text/x-mathjax-config">
 MathJax.Hub.Config({
 tex2jax: {
 inlineMath: [['$', '$'] ],
 displayMath: [ ['$$','$$'], ["\\[","\\]"] ]
 }
 });
</script>

# 4.2 画像分類と一般物体認識

画像分類はニューラルネットワークが主流。ニューラルネットワークは**特徴量を自動的に抽出できることから、非構造化データである画像の分析に向いている**。

活用例

- **顔認識** 
- **製造業の現場における品質管理**
- **スマート農業**

## 画像分類の技術の進歩

画像認識の最も強力な手法は**畳み込みニューラルネットワーク (CNN: Convolutional Neural Network)**。

畳み込みニューラルネットワークでは、前段での抽出結果を下流へ入力するといういことを繰り返すことで、層が深くなるについてれ、高度な特徴を抽出できるという性質がある。

CNNは、**畳み込み層**、**プーリング層**、**全結合層**の３種類のレイヤーから構成されている。

- **畳み込み層** 画像から特徴を抽出する
- **プーリング層** 重要な情報だけを残して情報圧縮する
- **全結合層** 抽出された特徴に基づいて、画像分類の結果を確率を表す数値として出力する

畳み込み層では、画像に対してカーネルと呼ばれる正方行列（3x3や5x5）がフィルタとして適用されることで、元の画像の特徴が強調された特徴マップが作成される。フィルタの処理は、元画像のピクセルとフィルタ行列の積和が計算される。エッジ検出用のカーネル、ぼかし用、シャープ化用など様々なカーネルがあるようだが、学習の仮定で複数のカーネルが訓練され、データに適した特徴を抽出するように自動で最適化される。

プーリング層では、重要な特徴を残しつつ画像の情報量を圧縮する。**最大プーリング**では、画像の小領域毎に最大の画素値だけを残す。**平均プーリング**は、平均値を残す。

## 一般物体認識

画像認識のなかでも画像分類は、１つの画像に対して被写体が◯◯というクラスに分類される確率を出力する。

画像の中に複数の物体があるときに、物体の予測を行う技術を **一般物体認識（Generic Object Recognition）** という。

一般物体認識は、 **物体検出(Object Detection / Localization)** と、 **画像分類(Classification)** の組み合わせとなる。

物体認識の手法としては、以下の方法がある。

- **物体領域を矩形で切り出す手法**
- **物体領域を画素単位で精密に切り出す手法** (セマンティックセグメンテーション)
- **両方を組み合わせた手法** (インスタンスセグメンテーション)

## 画像処理のための計算リソース

**GPU(Graphics Processing Unit)**: 大規模なテンソル（行列やベクトル）計算のような単純な処理を高速に行うことができ、並列演算処理が得意。GPUの演算能力を画像処理以外に汎用化されたGPGPUも開発された。

**CUDA**は、NVIDIAが提供しているGPGPUで並列演算を行う開発環境。他にGoogleは、テンソル計算に特化したTPUを開発している。

## データ拡張、転移学習

CNN（畳み込みニューラルネットワーク）では、パラメータが数千万個以上あり、言語処理用では数億個、数十億個を超える。

学習データを用意するコストを減らすための工夫

- **データ拡張**: データにランダムな変更（回転や平行移動など）を行うことで、人工的に訓練データのバリエーションを増やす
- **転移学習**: 膨大なデータで訓練した学習済みモデルの汎用的なパラメータ値を別のタスクに応用する。

転移学習における再訓練については以下のようなやり方がある

- (1) 新たに追加した「専用の層」のパラメータのみ訓練する
- (2) 出力層に近い側のパラメータのみ訓練し、上流のパラメータは固定する
- (3) 訓練済みモデルのすべてのパラメータを再訓練する

(2)や(3)、特に(3)は**ファインチューニング**と呼ばれる。時間はかかるが高い精度を出す可能性がある。

画像認識については、多くの学習済みモデルが公開されていて、転移学習に利用可能。（VGG16、ResNetなど）

## モデルの軽量化

- **プルーニング**: 枝刈り。比較的に汎化性能への寄与度の低い（ニューラルネットワークなどの）ノード間の接続を切る
- **蒸留**: 大規模モデル（教師モデル）への入力とその出力を用いて、小さいモデル（生徒モデル）を学習する
- **量子化**: パラメータをより小さいビット数で表現する




